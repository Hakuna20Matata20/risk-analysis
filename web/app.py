import os, sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import pandas as pd
from src.metrics import load_data, compute_metrics
from src.risk_score import compute_risk_score, normalize, load_bounds

st.title("üìä Risk Analysis Dashboard")

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–∏—Ö
df = load_data('data/tasks.csv')

# 2. –ü–æ–∫–∞–∑ –±–∞–∑–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
metrics = compute_metrics(df)
st.subheader("Core Metrics")
metrics_labels = {
    "total_tasks": "Total number of tasks",
    "critical_bugs": "Number of critical bugs",
    "blocked": "Number of blocked tasks",
    "avg_dev_days": "Average deviation between estimate and actual (days)",
    "added_mid_sprint": "Number of tasks added after sprint started",
    "avg_duration_days": "Average task duration (days)",
    "pct_on_estimate": "% of tasks completed within estimate",
    "total_bugs": "Total number of bugs",
    "total_reopened": "Number of reopened tasks"
}

# –í–∏–≤–µ–¥–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ —ñ–∑ –Ω–æ–≤–∏–º–∏ –Ω–∞–∑–≤–∞–º–∏
metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])
metrics_df.index = metrics_df.index.map(lambda x: metrics_labels.get(x, x))  # –º–∞–ø—ñ–Ω–≥ –Ω–∞ –∞–Ω–≥–ª—ñ–π—Å—å–∫—ñ –Ω–∞–∑–≤–∏
st.write(metrics_df)

# 3. –†–∏–∑–∏–∫–æ–≤–∏–π –±–∞–ª
bounds = load_bounds('data/history.csv')
risk = compute_risk_score(metrics, bounds)
st.subheader(f"Overall Risk Score: {risk}")

# 4. –î–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏
st.subheader("Metric Breakdown")
for k, v in metrics.items():
    label = metrics_labels.get(k, k)
    st.write(f"**{label}:** {v} (normalized: {round(normalize(v, *bounds[k]), 2)})")