import os, sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import pandas as pd
from src.metrics import load_data, compute_metrics
from src.risk_score import compute_risk_score, normalize, load_bounds

st.title("üìä Risk Analysis Dashboard")

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–∏—Ö
df = load_data('data/tasks.csv')

# 2. –ü–æ–∫–∞–∑ –±–∞–∑–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
metrics = compute_metrics(df)
st.subheader("Core Metrics")
metrics_labels = {
    "total_tasks": "–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–¥–∞—á",
    "critical_bugs": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –±–∞–≥—ñ–≤",
    "blocked": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–±–ª–æ–∫–æ–≤–∞–Ω–∏—Ö –∑–∞–¥–∞—á",
    "avg_dev_days": "–°–µ—Ä–µ–¥–Ω—î –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –º—ñ–∂ –æ—Ü—ñ–Ω–∫–æ—é —ñ —Ñ–∞–∫—Ç–æ–º (–¥–Ω—ñ)",
    "added_mid_sprint": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–¥–∞—á, –¥–æ–¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è –ø–æ—á–∞—Ç–∫—É —Å–ø—Ä–∏–Ω—Ç—É",
    "avg_duration_days": "–°–µ—Ä–µ–¥–Ω—è —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∑–∞–¥–∞—á (–¥–Ω—ñ)",
    "pct_on_estimate": "% –∑–∞–¥–∞—á, —â–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ñ –≤ –º–µ–∂–∞—Ö –æ—Ü—ñ–Ω–∫–∏",
    "total_bugs": "–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –±–∞–≥—ñ–≤",
    "total_reopened": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–≤—ñ–¥–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á"
}

# –í–∏–≤–µ–¥–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ —ñ–∑ –Ω–æ–≤–∏–º–∏ –Ω–∞–∑–≤–∞–º–∏
metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])
metrics_df.index = metrics_df.index.map(lambda x: metrics_labels.get(x, x))  # –º–∞–ø—ñ–Ω–≥ –Ω–∞ –ª—é–¥—Å—å–∫—ñ –Ω–∞–∑–≤–∏
st.write(metrics_df)

# 3. –†–∏–∑–∏–∫–æ–≤–∏–π –±–∞–ª
bounds = load_bounds('data/history.csv')
risk = compute_risk_score(metrics, bounds)
st.subheader(f"–ó–∞–≥–∞–ª—å–Ω–∏–π Risk Score: {risk}")

# 4. –î–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏
st.subheader("–î–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ –º–µ—Ç—Ä–∏–∫–∞—Ö")
for k, v in metrics.items():
    label = metrics_labels.get(k, k)
    st.write(f"**{label}:** {v} (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ: {round(normalize(v, *bounds[k]), 2)})")